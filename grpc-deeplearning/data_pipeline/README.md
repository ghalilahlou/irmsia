# IRMSIA Data Pipeline ğŸ“Š

**Pipeline complet pour importer, prÃ©parer et entraÃ®ner des modÃ¨les Deep Learning sur des datasets DICOM mÃ©dicaux**

---

## ğŸ¯ Vue d'Ensemble

Ce pipeline vous permet de :
- ğŸ“¥ **TÃ©lÃ©charger** des datasets mÃ©dicaux depuis plusieurs sources publiques
- ğŸ—‚ï¸ **Organiser** et indexer vos donnÃ©es
- ğŸ·ï¸ **Labelliser** et crÃ©er des splits train/val/test
- ğŸ§  **EntraÃ®ner** des modÃ¨les Deep Learning optimisÃ©s

---

## ğŸ“¦ Sources de DonnÃ©es Disponibles

### 1. **TCIA (The Cancer Imaging Archive)**
- ğŸ¥ Plus grande archive publique d'imagerie mÃ©dicale
- ğŸ“Š 100+ collections disponibles
- ğŸ”¬ Domaines: Cancer, Neurologie, Radiologie
- ğŸ’¾ Datasets DICOM natifs

**Datasets RecommandÃ©s:**
```python
# Nodules pulmonaires (Cancer du poumon)
LIDC-IDRI: 1,010 patients | 124 GB | CT

# Glioblastome (Tumeurs cÃ©rÃ©brales)
TCGA-GBM: 262 patients | 50 GB | MRI

# COVID-19 thoracique
COVID-19-AR: 201 patients | 15 GB | CT
```

### 2. **Kaggle Medical Imaging**
- ğŸ† Datasets de compÃ©titions + communautÃ©
- ğŸ“ˆ Datasets avec labels haute qualitÃ©
- âš¡ TÃ©lÃ©chargement rapide via API

**Datasets RecommandÃ©s:**
```python
# Brain MRI Segmentation
mateuszbuda/lgg-mri-segmentation
3,929 images | 1.5 GB | MRI + masks

# Chest X-Ray Pneumonia
paultimothymooney/chest-xray-pneumonia
5,863 images | 2.2 GB | X-Ray

# COVID-19 Radiography
tawsifurrahman/covid19-radiography-database
21,165 images | 1.2 GB | X-Ray
```

### 3. **NIH ChestX-ray14**
- ğŸ« 112,120 radiographies thoraciques
- ğŸ¥ 30,805 patients uniques
- ğŸ·ï¸ 14 pathologies labelisÃ©es
- ğŸ’¾ 42 GB (PNG format)

**Pathologies:**
```
1. Atelectasis      8. Pneumothorax
2. Cardiomegaly     9. Consolidation
3. Effusion         10. Edema
4. Infiltration     11. Emphysema
5. Mass             12. Fibrosis
6. Nodule           13. Pleural Thickening
7. Pneumonia        14. Hernia
```

---

## ğŸš€ Installation

### PrÃ©requis

```bash
Python >= 3.9
CUDA >= 11.7 (pour GPU)
```

### Installation des dÃ©pendances

```powershell
cd C:\Users\ghali\irmsia\grpc-deeplearning\data_pipeline

# Installer les dÃ©pendances
pip install -r requirements.txt

# Pour Kaggle (optionnel)
pip install kaggle
# Configurer API key: https://www.kaggle.com/docs/api
```

---

## ğŸ“– Guide de DÃ©marrage Rapide

### Option 1: Menu Interactif (RecommandÃ©)

```powershell
python data_pipeline_orchestrator.py
```

**Menu complet:**
```
ğŸ“¥ 1. TÃ©lÃ©charger des datasets
ğŸ“Š 2. GÃ©rer les datasets
ğŸ§  3. EntraÃ®ner un modÃ¨le
ğŸ“š 4. Documentation
```

### Option 2: Utilisation Programmatique

#### 1ï¸âƒ£ TÃ©lÃ©charger un Dataset

**Depuis TCIA:**
```python
from collectors.tcia_collector import TCIACollector

collector = TCIACollector(output_dir="datasets/tcia")

# Lister les collections
collections = collector.list_available_collections()

# TÃ©lÃ©charger une collection (10 premiers patients)
collector.download_collection(
    collection_name="COVID-19-AR",
    max_patients=10,
    modality="CT"
)
```

**Depuis Kaggle:**
```python
from collectors.kaggle_collector import KaggleCollector

collector = KaggleCollector(output_dir="datasets/kaggle")

# Rechercher des datasets
datasets = collector.search_datasets("brain mri")

# TÃ©lÃ©charger
collector.download_dataset("mateuszbuda/lgg-mri-segmentation")
```

**Depuis NIH:**
```python
from collectors.nih_collector import NIHCollector

collector = NIHCollector(output_dir="datasets/nih")

# TÃ©lÃ©charger les labels
collector.download_labels()

# Parser et crÃ©er splits
splits = collector.create_training_split()
```

#### 2ï¸âƒ£ Organiser et Indexer

```python
from processors.dataset_manager import DatasetManager

manager = DatasetManager(base_dir="datasets")

# Scanner un rÃ©pertoire
manager.scan_directory(
    directory="datasets/kaggle/brain_mri",
    dataset_name="brain_mri"
)

# CrÃ©er des splits train/val/test
splits = manager.create_train_val_test_split(
    dataset_name="brain_mri",
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15
)

# Voir les statistiques
stats = manager.get_dataset_statistics("brain_mri")
```

#### 3ï¸âƒ£ EntraÃ®ner un ModÃ¨le

```python
from training.training_pipeline import TrainingPipeline, create_default_model

# CrÃ©er le modÃ¨le
model = create_default_model(num_classes=2)

# CrÃ©er le pipeline
pipeline = TrainingPipeline(
    model=model,
    train_csv="datasets/brain_mri/splits/train.csv",
    val_csv="datasets/brain_mri/splits/val.csv",
    output_dir="training_outputs"
)

# EntraÃ®ner
pipeline.train(num_epochs=50)
```

---

## ğŸ”§ Utilisation en Ligne de Commande

### Collecter des DonnÃ©es

**TCIA:**
```powershell
# Voir les datasets recommandÃ©s
python collectors/tcia_collector.py --recommended

# Lister toutes les collections
python collectors/tcia_collector.py --list

# TÃ©lÃ©charger une collection
python collectors/tcia_collector.py --download COVID-19-AR --max-patients 10
```

**Kaggle:**
```powershell
# Voir les datasets recommandÃ©s
python collectors/kaggle_collector.py --recommended

# Rechercher
python collectors/kaggle_collector.py --search "brain tumor"

# TÃ©lÃ©charger
python collectors/kaggle_collector.py --download mateuszbuda/lgg-mri-segmentation
```

**NIH:**
```powershell
# Voir les datasets recommandÃ©s
python collectors/nih_collector.py --recommended

# TÃ©lÃ©charger les labels
python collectors/nih_collector.py --download-labels

# CrÃ©er un split
python collectors/nih_collector.py --create-split
```

### GÃ©rer les Datasets

```powershell
# Scanner un rÃ©pertoire
python processors/dataset_manager.py --scan datasets/kaggle/brain_mri --dataset-name brain_mri

# CrÃ©er un split
python processors/dataset_manager.py --create-split brain_mri

# Voir le rÃ©sumÃ©
python processors/dataset_manager.py --summary
```

### EntraÃ®ner un ModÃ¨le

```powershell
python training/training_pipeline.py \
    --train-csv datasets/brain_mri/splits/train.csv \
    --val-csv datasets/brain_mri/splits/val.csv \
    --num-classes 2 \
    --epochs 50
```

---

## ğŸ“Š Workflow Complet: Exemple Pratique

### ScÃ©nario: DÃ©tection de Pneumonie sur X-Rays

```powershell
# 1. TÃ©lÃ©charger le dataset Kaggle
python collectors/kaggle_collector.py --download paultimothymooney/chest-xray-pneumonia

# 2. Indexer le dataset
python processors/dataset_manager.py \
    --scan datasets/kaggle/paultimothymooney_chest-xray-pneumonia \
    --dataset-name pneumonia

# 3. CrÃ©er les splits
python processors/dataset_manager.py --create-split pneumonia

# 4. EntraÃ®ner le modÃ¨le
python training/training_pipeline.py \
    --train-csv datasets/pneumonia/splits/train.csv \
    --val-csv datasets/pneumonia/splits/val.csv \
    --num-classes 2 \
    --epochs 30

# 5. RÃ©sultats disponibles dans:
#    training_outputs/run_YYYYMMDD_HHMMSS/
#    - best_model.pth
#    - training_curves.png
#    - training_history.json
```

---

## ğŸ“ Structure du Pipeline

```
data_pipeline/
â”œâ”€â”€ collectors/               # TÃ©lÃ©chargement de datasets
â”‚   â”œâ”€â”€ tcia_collector.py    # The Cancer Imaging Archive
â”‚   â”œâ”€â”€ kaggle_collector.py  # Kaggle datasets
â”‚   â””â”€â”€ nih_collector.py     # NIH ChestX-ray14
â”‚
â”œâ”€â”€ processors/              # PrÃ©paration des donnÃ©es
â”‚   â””â”€â”€ dataset_manager.py   # Indexation, splits, export
â”‚
â”œâ”€â”€ training/                # EntraÃ®nement
â”‚   â””â”€â”€ training_pipeline.py # Pipeline complet
â”‚
â”œâ”€â”€ datasets/                # DonnÃ©es tÃ©lÃ©chargÃ©es (crÃ©Ã© auto)
â”‚   â”œâ”€â”€ tcia/
â”‚   â”œâ”€â”€ kaggle/
â”‚   â”œâ”€â”€ nih/
â”‚   â””â”€â”€ dataset_index.json  # Index central
â”‚
â”œâ”€â”€ training_outputs/        # ModÃ¨les entraÃ®nÃ©s (crÃ©Ã© auto)
â”‚   â””â”€â”€ run_YYYYMMDD_HHMMSS/
â”‚       â”œâ”€â”€ best_model.pth
â”‚       â”œâ”€â”€ training_curves.png
â”‚       â””â”€â”€ training_history.json
â”‚
â””â”€â”€ data_pipeline_orchestrator.py  # Menu interactif
```

---

## ğŸ“ Datasets RecommandÃ©s par Use Case

### ğŸ§  Neurologie (Brain Imaging)

| Dataset | Source | Images | Size | Format | Pathologie |
|---------|--------|--------|------|--------|-----------|
| TCGA-GBM | TCIA | 262 patients | 50 GB | DICOM | Glioblastome |
| TCGA-LGG | TCIA | 199 patients | 40 GB | DICOM | Gliome bas grade |
| Brain MRI Segmentation | Kaggle | 3,929 | 1.5 GB | DICOM + masks | Gliome |

### ğŸ« Thoracique (Chest Imaging)

| Dataset | Source | Images | Size | Format | Pathologie |
|---------|--------|--------|------|--------|-----------|
| NIH ChestX-ray14 | NIH | 112,120 | 42 GB | PNG | 14 pathologies |
| LIDC-IDRI | TCIA | 1,010 patients | 124 GB | DICOM | Nodules pulmonaires |
| Chest X-Ray Pneumonia | Kaggle | 5,863 | 2.2 GB | JPG | Pneumonie |
| COVID-19 Radiography | Kaggle | 21,165 | 1.2 GB | PNG | COVID-19 |

### ğŸ¦´ Autres Domaines

| Dataset | Source | Images | Size | Pathologie |
|---------|--------|--------|------|-----------|
| RSNA Pneumonia | Kaggle Comp | 30,000 | 25 GB | Pneumonie |
| RSNA Hemorrhage | Kaggle Comp | 752,803 | 70 GB | HÃ©morragie IC |
| RSNA Breast Cancer | Kaggle Comp | 54,706 | 300 GB | Cancer du sein |

---

## ğŸ”¥ FonctionnalitÃ©s AvancÃ©es

### 1. Fusion de Datasets

```python
manager = DatasetManager()

# Fusionner plusieurs datasets
manager.merge_datasets(
    dataset_names=["brain_mri_1", "brain_mri_2", "brain_mri_3"],
    output_name="brain_mri_combined"
)
```

### 2. Filtrage par Pathologie

```python
# NIH - Filtrer uniquement les pneumonies
df = nih_collector.parse_labels()
pneumonia_df = df[df['Pneumonia'] == 1]
```

### 3. Export pour Frameworks Externes

```python
# Exporter pour PyTorch, TensorFlow, etc.
manager.export_for_training(
    dataset_name="pneumonia",
    split="train",
    output_format="json"  # ou "csv", "txt"
)
```

### 4. Augmentation de DonnÃ©es

Le `TrainingPipeline` inclut automatiquement:
- Rotation alÃ©atoire
- Flip horizontal/vertical
- Zoom alÃ©atoire
- Bruit gaussien
- Ajustement de contraste

---

## ğŸ“ˆ RÃ©sultats d'EntraÃ®nement

AprÃ¨s entraÃ®nement, vous obtenez:

```
training_outputs/run_20231202_150000/
â”œâ”€â”€ best_model.pth              # Meilleur modÃ¨le (val loss minimale)
â”œâ”€â”€ final_model.pth             # ModÃ¨le final
â”œâ”€â”€ checkpoint_epoch_10.pth     # Checkpoints intermÃ©diaires
â”œâ”€â”€ training_curves.png         # Courbes Loss/Accuracy
â””â”€â”€ training_history.json       # Historique complet
```

**training_history.json:**
```json
{
  "train_loss": [0.8, 0.6, 0.4, ...],
  "val_loss": [0.7, 0.5, 0.3, ...],
  "train_acc": [60, 70, 85, ...],
  "val_acc": [65, 75, 88, ...]
}
```

---

## ğŸ”§ Configuration AvancÃ©e

### Custom Training Configuration

```python
# Modifier les hyperparamÃ¨tres
pipeline = TrainingPipeline(
    model=model,
    train_csv="train.csv",
    val_csv="val.csv"
)

# Modifier optimizer
pipeline.optimizer = torch.optim.SGD(
    model.parameters(),
    lr=0.01,
    momentum=0.9
)

# Modifier loss
pipeline.criterion = nn.BCEWithLogitsLoss()

# EntraÃ®ner
pipeline.train(num_epochs=100)
```

---

## â“ FAQ

### Q: Combien d'espace disque nÃ©cessaire?

**Exemples:**
- **Petit projet (test):** 5-10 GB
  - Brain MRI Segmentation (1.5 GB)
  - COVID-19 Radiography (1.2 GB)
  
- **Projet moyen:** 50-100 GB
  - TCGA-GBM (50 GB)
  - NIH ChestX-ray (42 GB)

- **Grand projet:** 200+ GB
  - LIDC-IDRI (124 GB)
  - RSNA Competitions (70-300 GB)

### Q: Quel GPU pour l'entraÃ®nement?

**Minimum:** NVIDIA GTX 1060 (6GB VRAM)  
**RecommandÃ©:** RTX 3060+ (12GB VRAM)  
**Optimal:** RTX 4090 / A100 (24+ GB VRAM)

**Sans GPU:** CPU possible mais ~10x plus lent

### Q: Temps de tÃ©lÃ©chargement?

**DÃ©pend de votre connexion:**
- 10 GB @ 100 Mbps: ~15 min
- 50 GB @ 100 Mbps: ~1h15
- 124 GB @ 100 Mbps: ~3h

**Conseil:** Commencez par de petits datasets pour tester!

### Q: Format DICOM vs PNG/JPG?

**DICOM (Natif):**
- âœ… PrÃ©serve 16-bit (65,536 nuances)
- âœ… MÃ©tadonnÃ©es mÃ©dicales
- âœ… +5-10% prÃ©cision diagnostique
- âš ï¸ Fichiers plus lourds

**PNG/JPG (Converti):**
- âœ… Fichiers plus lÃ©gers
- âœ… Compatible partout
- âš ï¸ 8-bit seulement (256 nuances)
- âš ï¸ Perte de mÃ©tadonnÃ©es

**Recommandation:** DICOM pour training, PNG pour inference rapide

---

## ğŸ†˜ Support & DÃ©pannage

### Erreur: "Kaggle API not configured"

```powershell
# 1. CrÃ©er compte Kaggle
# 2. GÃ©nÃ©rer API token: https://www.kaggle.com/account
# 3. Placer kaggle.json dans:
#    Windows: C:\Users\<user>\.kaggle\kaggle.json
#    Linux: ~/.kaggle/kaggle.json

# 4. Tester
kaggle datasets list
```

### Erreur: "CUDA out of memory"

```python
# RÃ©duire le batch size
pipeline.train_loader = DataLoader(
    pipeline.train_dataset,
    batch_size=8,  # Au lieu de 32
    ...
)
```

### Erreur: "DICOM file not found"

```python
# VÃ©rifier les chemins dans le CSV
df = pd.read_csv("train.csv")
print(df['path'].head())

# Les chemins doivent Ãªtre relatifs Ã  base_dir
# ou absolus
```

---

## ğŸ“š Ressources Externes

**TCIA:**
- Site: https://www.cancerimagingarchive.net/
- API: https://wiki.cancerimagingarchive.net/display/Public/TCIA+Programmatic+Interface

**Kaggle:**
- Site: https://www.kaggle.com/datasets
- API: https://github.com/Kaggle/kaggle-api

**NIH:**
- ChestX-ray14: https://nihcc.app.box.com/v/ChestXray-NIHCC
- Paper: https://arxiv.org/abs/1705.02315

**MONAI (Medical AI):**
- Docs: https://docs.monai.io/
- Tutorials: https://github.com/Project-MONAI/tutorials

---

## ğŸ“„ License

Ce pipeline est fourni pour usage Ã©ducatif et recherche.

**Note:** Chaque dataset a sa propre license. Consultez les sources pour les conditions d'utilisation.

---

## ğŸ™ CrÃ©dits

- **TCIA:** The Cancer Imaging Archive
- **NIH:** National Institutes of Health
- **Kaggle:** Community datasets
- **MONAI:** Medical Open Network for AI

---

## ğŸ“ Contact

Pour questions et support:
- ğŸ“§ Email: [votre email]
- ğŸ’¬ Issues: [GitHub repo]

---

**âœ¨ Bon entraÃ®nement! ğŸš€**

