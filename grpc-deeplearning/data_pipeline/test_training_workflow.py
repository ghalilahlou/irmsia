"""
Test Training Workflow - Brain MRI Dataset
Script de test pour valider le pipeline d'entra√Ænement complet
"""

import sys
import io
from pathlib import Path
import logging
import torch
from datetime import datetime

# Fix Windows console encoding
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except:
        pass

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Import du training pipeline
from training.training_pipeline import TrainingPipeline, create_default_model


def test_training_workflow():
    """
    Test complet du workflow d'entra√Ænement
    """
    
    print("\n" + "="*70)
    print("TEST TRAINING WORKFLOW - BRAIN MRI DATASET")
    print("="*70)
    
    # Configuration
    config = {
        'train_csv': 'datasets/brain_mri/splits/train.csv',
        'val_csv': 'datasets/brain_mri/splits/val.csv',
        'test_csv': 'datasets/brain_mri/splits/test.csv',
        'num_classes': 2,  # Gliome vs Normal (mais ce dataset ne contient que des gliomes)
        'num_epochs': 5,   # 5 epochs pour test rapide
        'output_dir': 'training_outputs/test_brain_mri'
    }
    
    print(f"\nüìä Configuration:")
    print(f"   Train CSV: {config['train_csv']}")
    print(f"   Val CSV: {config['val_csv']}")
    print(f"   Classes: {config['num_classes']}")
    print(f"   Epochs: {config['num_epochs']}")
    print(f"   Output: {config['output_dir']}")
    
    # V√©rifier que les fichiers existent
    print(f"\nüîç V√©rification des fichiers...")
    train_file = Path(config['train_csv'])
    val_file = Path(config['val_csv'])
    test_file = Path(config['test_csv'])
    
    if not train_file.exists():
        print(f"‚ùå ERREUR: Fichier train non trouv√©: {train_file}")
        print(f"   Ex√©cutez d'abord: python create_brain_mri_split.py")
        return False
    
    if not val_file.exists():
        print(f"‚ùå ERREUR: Fichier val non trouv√©: {val_file}")
        return False
    
    print(f"‚úÖ Train file: {train_file} (existe)")
    print(f"‚úÖ Val file: {val_file} (existe)")
    
    # Compter les images
    import pandas as pd
    train_df = pd.read_csv(train_file)
    val_df = pd.read_csv(val_file)
    
    print(f"\nüìà Statistiques:")
    print(f"   Images training: {len(train_df)}")
    print(f"   Images validation: {len(val_df)}")
    print(f"   Total: {len(train_df) + len(val_df)}")
    
    # V√©rifier CUDA
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nüíª Device:")
    if device == 'cuda':
        print(f"   ‚úÖ CUDA disponible: {torch.cuda.get_device_name(0)}")
        print(f"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print(f"   ‚ö†Ô∏è  CPU mode (plus lent)")
    
    # Cr√©er le mod√®le
    print(f"\nüß† Cr√©ation du mod√®le...")
    try:
        model = create_default_model(num_classes=config['num_classes'])
        num_params = sum(p.numel() for p in model.parameters())
        print(f"   ‚úÖ Mod√®le cr√©√©: EfficientNet-B0")
        print(f"   Param√®tres: {num_params:,}")
    except Exception as e:
        print(f"   ‚ùå Erreur cr√©ation mod√®le: {e}")
        return False
    
    # Cr√©er le pipeline de training
    print(f"\nüöÄ Initialisation du pipeline...")
    try:
        pipeline = TrainingPipeline(
            model=model,
            train_csv=config['train_csv'],
            val_csv=config['val_csv'],
            output_dir=config['output_dir'],
            device=device
        )
        print(f"   ‚úÖ Pipeline initialis√©")
        print(f"   Batch size: 32")
        print(f"   Optimizer: AdamW (lr=1e-4)")
        print(f"   Scheduler: CosineAnnealingLR")
    except Exception as e:
        print(f"   ‚ùå Erreur pipeline: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Lancer l'entra√Ænement
    print(f"\n" + "="*70)
    print(f"üéØ D√âMARRAGE DE L'ENTRA√éNEMENT")
    print(f"="*70)
    print(f"\n‚è±Ô∏è  Temps estim√©:")
    if device == 'cuda':
        print(f"   - Avec GPU: ~5-10 minutes ({config['num_epochs']} epochs)")
    else:
        print(f"   - Avec CPU: ~30-45 minutes ({config['num_epochs']} epochs)")
    print(f"\nüí° Le training va commencer. Vous verrez:")
    print(f"   - Progress bar par epoch")
    print(f"   - Loss et accuracy apr√®s chaque epoch")
    print(f"   - Sauvegarde du meilleur mod√®le")
    print(f"\n" + "-"*70)
    
    start_time = datetime.now()
    
    try:
        # Entra√Æner
        pipeline.train(
            num_epochs=config['num_epochs'],
            early_stopping_patience=3  # Stop si pas d'am√©lioration apr√®s 3 epochs
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"\n" + "="*70)
        print(f"‚úÖ ENTRA√éNEMENT TERMIN√â!")
        print(f"="*70)
        print(f"\n‚è±Ô∏è  Dur√©e: {duration/60:.1f} minutes ({duration:.0f} secondes)")
        print(f"üìä Epochs: {config['num_epochs']}")
        print(f"üíæ Mod√®les sauvegard√©s dans: {pipeline.run_dir}")
        
        # Afficher le r√©sum√©
        history = pipeline.history
        print(f"\nüìà R√©sultats finaux:")
        print(f"   Train Loss: {history['train_loss'][-1]:.4f}")
        print(f"   Val Loss: {history['val_loss'][-1]:.4f}")
        print(f"   Train Acc: {history['train_acc'][-1]:.2f}%")
        print(f"   Val Acc: {history['val_acc'][-1]:.2f}%")
        
        # Trouver la meilleure epoch
        best_epoch = history['val_loss'].index(min(history['val_loss'])) + 1
        best_val_loss = min(history['val_loss'])
        best_val_acc = history['val_acc'][best_epoch - 1]
        
        print(f"\nüèÜ Meilleure epoch: {best_epoch}")
        print(f"   Val Loss: {best_val_loss:.4f}")
        print(f"   Val Acc: {best_val_acc:.2f}%")
        
        # Fichiers g√©n√©r√©s
        print(f"\nüìÅ Fichiers g√©n√©r√©s:")
        print(f"   ‚úÖ best_model.pth - Meilleur mod√®le")
        print(f"   ‚úÖ final_model.pth - Mod√®le final")
        print(f"   ‚úÖ training_curves.png - Courbes d'apprentissage")
        print(f"   ‚úÖ training_history.json - Historique complet")
        
        # Analyse des r√©sultats
        print(f"\nüîç Analyse:")
        
        if best_val_acc > 70:
            print(f"   ‚úÖ EXCELLENT - Accuracy > 70%")
            print(f"      Le mod√®le apprend correctement!")
        elif best_val_acc > 50:
            print(f"   ‚ö†Ô∏è  MOYEN - Accuracy 50-70%")
            print(f"      Le mod√®le apprend mais peut √™tre am√©lior√©")
        else:
            print(f"   ‚ùå FAIBLE - Accuracy < 50%")
            print(f"      Le mod√®le n'apprend pas bien (normal pour un test rapide)")
        
        # V√©rifier overfitting
        train_acc = history['train_acc'][-1]
        val_acc = history['val_acc'][-1]
        gap = train_acc - val_acc
        
        if gap < 5:
            print(f"   ‚úÖ Pas d'overfitting (gap: {gap:.1f}%)")
        elif gap < 15:
            print(f"   ‚ö†Ô∏è  L√©ger overfitting possible (gap: {gap:.1f}%)")
        else:
            print(f"   ‚ö†Ô∏è  Overfitting d√©tect√© (gap: {gap:.1f}%)")
            print(f"      Train Acc: {train_acc:.1f}% | Val Acc: {val_acc:.1f}%")
        
        print(f"\n" + "="*70)
        print(f"üéâ TEST R√âUSSI - PIPELINE FONCTIONNEL!")
        print(f"="*70)
        
        return True
        
    except KeyboardInterrupt:
        print(f"\n\n‚ö†Ô∏è  Training interrompu par l'utilisateur")
        print(f"   Progression sauvegard√©e dans: {pipeline.run_dir}")
        return False
        
    except Exception as e:
        print(f"\n‚ùå ERREUR pendant l'entra√Ænement:")
        print(f"   {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Point d'entr√©e principal"""
    
    print("\n" + "="*70)
    print("IRMSIA - TEST DE TRAINING WORKFLOW")
    print("="*70)
    print(f"\nüìö Ce script va:")
    print(f"   1. Charger le dataset Brain MRI")
    print(f"   2. Cr√©er un mod√®le Deep Learning (EfficientNet-B0)")
    print(f"   3. Entra√Æner pendant 5 epochs")
    print(f"   4. Sauvegarder les r√©sultats")
    print(f"   5. Afficher un rapport complet")
    
    input(f"\n‚è∏Ô∏è  Appuyez sur Enter pour continuer...")
    
    success = test_training_workflow()
    
    if success:
        print(f"\n‚úÖ Le pipeline de training est op√©rationnel!")
        print(f"\nüìñ Prochaines √©tapes:")
        print(f"   1. Voir les courbes: training_outputs/test_brain_mri/run_*/training_curves.png")
        print(f"   2. Lancer un training complet: 50 epochs au lieu de 5")
        print(f"   3. Tester avec d'autres datasets (COVID-19, etc.)")
        print(f"   4. Int√©grer avec le serveur gRPC")
    else:
        print(f"\n‚ö†Ô∏è  Le test a √©chou√©. V√©rifiez les erreurs ci-dessus.")
        print(f"\nüí° Solutions possibles:")
        print(f"   - V√©rifier que les CSV existent: datasets/brain_mri/splits/")
        print(f"   - R√©duire le batch_size si erreur de m√©moire")
        print(f"   - Installer les d√©pendances: pip install -r requirements.txt")
    
    print(f"\n" + "="*70)
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())

