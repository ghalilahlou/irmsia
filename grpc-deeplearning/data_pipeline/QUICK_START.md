# Quick Start Guide - Data Pipeline üöÄ

**D√©marrez avec le pipeline de donn√©es en 10 minutes!**

---

## ‚ö° Installation Ultra-Rapide (2 min)

```powershell
# 1. Aller dans le r√©pertoire
cd C:\Users\ghali\irmsia\grpc-deeplearning\data_pipeline

# 2. Installer les d√©pendances
pip install -r requirements.txt

# 3. (Optionnel) Configurer Kaggle
pip install kaggle
# Placer votre kaggle.json dans: C:\Users\ghali\.kaggle\kaggle.json
```

---

## üéØ Sc√©nario 1: Test Rapide avec Menu Interactif

### Temps estim√©: 10 minutes

```powershell
# Lancer le menu interactif
python data_pipeline_orchestrator.py
```

**Workflow sugg√©r√©:**

1. **Menu Principal ‚Üí 4. Documentation**
   - Voir les datasets recommand√©s
   - Choisir un petit dataset (~1-2 GB)

2. **Menu Principal ‚Üí 1. T√©l√©charger des datasets**
   - S√©lectionner Kaggle
   - T√©l√©charger "Brain MRI Segmentation" (1.5 GB)

3. **Menu Principal ‚Üí 2. G√©rer les datasets**
   - Scanner le r√©pertoire t√©l√©charg√©
   - Cr√©er un split train/val/test

4. **Menu Principal ‚Üí 3. Entra√Æner un mod√®le**
   - Fournir les CSV g√©n√©r√©s
   - Lancer l'entra√Ænement

---

## üß™ Sc√©nario 2: Test avec un Mini-Dataset (5 min)

**Utilisons le dataset COVID-19 de Kaggle (1.2 GB, 21k images)**

```powershell
# 1. T√©l√©charger
python collectors/kaggle_collector.py --download tawsifurrahman/covid19-radiography-database

# 2. Scanner
python processors/dataset_manager.py --scan "datasets/kaggle/tawsifurrahman_covid19-radiography-database" --dataset-name covid19

# 3. Cr√©er split
python processors/dataset_manager.py --create-split covid19

# 4. Voir le r√©sum√©
python processors/dataset_manager.py --summary
```

**R√©sultat:**
```
üìä Total Images: 21,165
üìÅ Datasets: covid19
   - Train: 70% (14,815 images)
   - Val: 15% (3,174 images)
   - Test: 15% (3,176 images)
```

---

## üè• Sc√©nario 3: Projet R√©el - D√©tection de Pneumonie

### Temps estim√©: 1-2 heures (selon connexion)

**Dataset:** Chest X-Ray Pneumonia (5,863 images, 2.2 GB)

### √âtape 1: T√©l√©chargement (10-30 min)

```powershell
python collectors/kaggle_collector.py --download paultimothymooney/chest-xray-pneumonia
```

### √âtape 2: Organisation (5 min)

```powershell
# Scanner le dataset
python processors/dataset_manager.py \
    --scan "datasets/kaggle/paultimothymooney_chest-xray-pneumonia" \
    --dataset-name pneumonia_xray

# Cr√©er les splits
python processors/dataset_manager.py --create-split pneumonia_xray

# V√©rifier
python processors/dataset_manager.py --summary
```

### √âtape 3: Entra√Ænement (30-60 min selon GPU)

```powershell
python training/training_pipeline.py \
    --train-csv "datasets/pneumonia_xray/splits/train.csv" \
    --val-csv "datasets/pneumonia_xray/splits/val.csv" \
    --num-classes 2 \
    --epochs 30
```

**R√©sultats attendus:**
- Accuracy: ~85-90%
- Mod√®le sauvegard√©: `training_outputs/run_YYYYMMDD_HHMMSS/best_model.pth`
- Courbes: `training_curves.png`

### √âtape 4: √âvaluation

```python
# Charger le mod√®le
import torch
model = torch.load("training_outputs/run_*/best_model.pth")

# Inf√©rence (voir training_pipeline.py)
```

---

## üß† Sc√©nario 4: Projet Neurologie - Brain MRI

### Temps estim√©: 30 min - 1h

**Dataset:** LGG MRI Segmentation (3,929 images, 1.5 GB)

```powershell
# 1. T√©l√©charger
python collectors/kaggle_collector.py --download mateuszbuda/lgg-mri-segmentation

# 2. Pr√©parer
python processors/dataset_manager.py \
    --scan "datasets/kaggle/mateuszbuda_lgg-mri-segmentation" \
    --dataset-name brain_mri_lgg

python processors/dataset_manager.py --create-split brain_mri_lgg

# 3. Entra√Æner
python training/training_pipeline.py \
    --train-csv "datasets/brain_mri_lgg/splits/train.csv" \
    --val-csv "datasets/brain_mri_lgg/splits/val.csv" \
    --num-classes 2 \
    --epochs 40
```

---

## üìä Sc√©nario 5: Grand Dataset - TCIA

### Temps estim√©: Plusieurs heures (dataset lourd)

**‚ö†Ô∏è Recommand√© uniquement si vous avez:**
- Beaucoup d'espace disque (50+ GB)
- Bonne connexion internet
- GPU puissant pour training

```powershell
# 1. Voir les collections disponibles
python collectors/tcia_collector.py --recommended

# 2. T√©l√©charger COVID-19-AR (15 GB, 201 patients)
python collectors/tcia_collector.py --download COVID-19-AR --max-patients 50

# 3. Pr√©parer
python processors/dataset_manager.py \
    --scan "datasets/tcia/COVID-19-AR" \
    --dataset-name covid_ct_tcia

python processors/dataset_manager.py --create-split covid_ct_tcia

# 4. Entra√Æner
python training/training_pipeline.py \
    --train-csv "datasets/covid_ct_tcia/splits/train.csv" \
    --val-csv "datasets/covid_ct_tcia/splits/val.csv" \
    --num-classes 2 \
    --epochs 50
```

---

## üêç Utilisation Programmatique (Python)

### Exemple Complet en Python

```python
# complete_workflow.py
from collectors.kaggle_collector import KaggleCollector
from processors.dataset_manager import DatasetManager
from training.training_pipeline import TrainingPipeline, create_default_model

# 1. T√©l√©charger
print("üì• T√©l√©chargement...")
kaggle = KaggleCollector()
kaggle.download_dataset("tawsifurrahman/covid19-radiography-database")

# 2. Organiser
print("üóÇÔ∏è Organisation...")
manager = DatasetManager()
manager.scan_directory(
    directory="datasets/kaggle/tawsifurrahman_covid19-radiography-database",
    dataset_name="covid19"
)

# 3. Cr√©er splits
print("‚úÇÔ∏è Cr√©ation des splits...")
splits = manager.create_train_val_test_split("covid19")

# 4. Entra√Æner
print("üß† Entra√Ænement...")
model = create_default_model(num_classes=3)  # COVID, Normal, Viral Pneumonia

pipeline = TrainingPipeline(
    model=model,
    train_csv="datasets/covid19/splits/train.csv",
    val_csv="datasets/covid19/splits/val.csv"
)

pipeline.train(num_epochs=30)

print("‚úÖ Termin√©!")
```

**Lancer:**
```powershell
python complete_workflow.py
```

---

## üìã Checklist de D√©marrage

### Avant de Commencer

- [ ] Python 3.9+ install√©
- [ ] pip √† jour (`python -m pip install --upgrade pip`)
- [ ] CUDA install√© (si GPU disponible)
- [ ] Espace disque suffisant (min 10 GB)

### Installation

- [ ] D√©pendances install√©es (`pip install -r requirements.txt`)
- [ ] Kaggle API configur√©e (si utilisation Kaggle)
- [ ] Tests des imports (`python -c "import torch; import monai"`)

### Premier Test

- [ ] Menu interactif lance sans erreur
- [ ] Un petit dataset t√©l√©charg√© avec succ√®s
- [ ] Dataset index√© correctement
- [ ] Split cr√©√© avec succ√®s
- [ ] Entra√Ænement d√©marre (m√™me 1 epoch)

---

## üéØ Datasets Recommand√©s par Niveau

### üë∂ D√©butant (Test rapide)

| Dataset | Size | Time | Complexit√© |
|---------|------|------|-----------|
| COVID-19 Radiography (Kaggle) | 1.2 GB | 10 min | ‚≠ê |
| Brain MRI Segmentation (Kaggle) | 1.5 GB | 15 min | ‚≠ê‚≠ê |

### üë®‚Äçüíª Interm√©diaire (Projet r√©el)

| Dataset | Size | Time | Complexit√© |
|---------|------|------|-----------|
| Chest X-Ray Pneumonia (Kaggle) | 2.2 GB | 30 min | ‚≠ê‚≠ê‚≠ê |
| COVID-19-AR (TCIA) | 15 GB | 1-2h | ‚≠ê‚≠ê‚≠ê |

### üßë‚Äçüî¨ Avanc√© (Research)

| Dataset | Size | Time | Complexit√© |
|---------|------|------|-----------|
| NIH ChestX-ray14 | 42 GB | 3-5h | ‚≠ê‚≠ê‚≠ê‚≠ê |
| LIDC-IDRI (TCIA) | 124 GB | 1 jour | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

## ‚ö†Ô∏è Probl√®mes Courants

### 1. "Kaggle API not configured"

**Solution:**
```powershell
# 1. Aller sur: https://www.kaggle.com/account
# 2. Cliquer "Create New API Token"
# 3. Placer kaggle.json dans: C:\Users\ghali\.kaggle\
# 4. V√©rifier: kaggle datasets list
```

### 2. "CUDA out of memory"

**Solution:**
```python
# R√©duire batch_size dans training_pipeline.py:
batch_size=8  # Au lieu de 32
```

### 3. "Dataset directory not found"

**Solution:**
```powershell
# V√©rifier les chemins
python processors/dataset_manager.py --summary

# Les chemins doivent exister et contenir des fichiers DICOM/images
```

### 4. "Import Error: No module named 'monai'"

**Solution:**
```powershell
pip install monai
# Ou r√©installer toutes les d√©pendances:
pip install -r requirements.txt --force-reinstall
```

---

## üí° Conseils Pro

### 1. Commencez Petit
- Testez avec 1-2 GB avant de t√©l√©charger 100+ GB
- Utilisez `--max-patients` pour limiter les t√©l√©chargements TCIA

### 2. Surveillez l'Espace Disque
```powershell
# Windows
Get-PSDrive C | Select-Object Used,Free

# Voir la taille des datasets
python processors/dataset_manager.py --summary
```

### 3. Utilisez un SSD pour Training
- Acc√©l√®re le chargement des images (~2x)
- Place datasets sur SSD si possible

### 4. Checkpoints R√©guliers
- Le pipeline sauvegarde automatiquement tous les 10 epochs
- Vous pouvez reprendre si interruption

### 5. Augmentation de Donn√©es
```python
# Le pipeline inclut d√©j√†:
- Rotation al√©atoire
- Flip H/V
- Zoom
- Bruit gaussien
- Ajustement contraste
```

---

## üéì Prochaines √âtapes

### Apr√®s votre Premier Mod√®le

1. **√âvaluation Approfondie**
   - Matrice de confusion
   - ROC curves
   - Pr√©cision par classe

2. **Optimisation**
   - Hyperparameter tuning
   - Architecture diff√©rente
   - Transfer learning

3. **Int√©gration IRMSIA**
   - Connecter avec gRPC server
   - Int√©gration Blockchain
   - Interface web

4. **Production**
   - Export ONNX
   - Optimisation inference
   - D√©ploiement

---

## üìö Ressources Utiles

**Documentation:**
- PyTorch: https://pytorch.org/docs/
- MONAI: https://docs.monai.io/
- Kaggle API: https://github.com/Kaggle/kaggle-api

**Tutoriels:**
- Medical Imaging DL: https://github.com/Project-MONAI/tutorials
- PyTorch Medical: https://pytorch.org/blog/medical-imaging/

**Papers:**
- NIH ChestX-ray14: https://arxiv.org/abs/1705.02315
- COVID-19 Detection: https://arxiv.org/abs/2003.13145

---

## üöÄ Vous √™tes Pr√™t!

Choisissez un sc√©nario ci-dessus et lancez-vous!

**Recommandation:**
- Premi√®re fois? ‚Üí **Sc√©nario 1** (Menu interactif)
- D√©j√† √† l'aise? ‚Üí **Sc√©nario 3** (Pneumonie)
- Projet s√©rieux? ‚Üí **Sc√©nario 4** ou **5**

**Bonne chance! üéâ**

